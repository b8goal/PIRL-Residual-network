{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Residual Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR-100 데이터 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from six.moves import urllib\n",
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# from tf.keras.utils import get_file\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.datasets.cifar import load_batch\n",
    "from keras import backend as K\n",
    "\n",
    "def load_data(label_mode='fine'):\n",
    "    if label_mode not in ['fine', 'coarse']:\n",
    "        raise ValueError('`label_mode` must be one of `\"fine\"`, `\"coarse\"`.')\n",
    "\n",
    "    dirname = 'cifar-100-python'\n",
    "    origin = 'https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz'\n",
    "    path = get_file(dirname, origin=origin, untar=True)\n",
    "\n",
    "    fpath = os.path.join(path, 'train')\n",
    "    x_train, y_train = load_batch(fpath, label_key=label_mode + '_labels')\n",
    "\n",
    "    fpath = os.path.join(path, 'test')\n",
    "    x_test, y_test = load_batch(fpath, label_key=label_mode + '_labels')\n",
    "\n",
    "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "    y_test = np.reshape(y_test, (len(y_test), 1))\n",
    "\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        x_train = x_train.transpose(0, 2, 3, 1)\n",
    "        x_test = x_test.transpose(0, 2, 3, 1)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "(train_data,train_label),(test_data,test_label) = load_data()\n",
    "train_data = train_data / 255.0\n",
    "test_data = test_data / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# size of cifar-100\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show data\n",
    "_, (ax1) = plt.subplots(1)\n",
    "sample_data = train_data[100]\n",
    "ax1.imshow(sample_data, cmap=plt.cm.Greys);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### residual block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(X_input, num_filter, chg_dim) :\n",
    "    stride = 1\n",
    "        \n",
    "    #stride=2일 경우\n",
    "    if chg_dim :\n",
    "        stride = 2\n",
    "        pool1 = tf.layers.max_pooling2d(inputs= X_input, strides=2, pool_size=[2,2])\n",
    "        pad1 = tf.pad(pool1, [[0,0], [0,0], [0,0], [int(num_filter/4),int(num_filter/4)]])\n",
    "        shortcut = pad1\n",
    "    else :\n",
    "        shortcut = X_input\n",
    "        \n",
    "    bm1 = tf.layers.batch_normalization(inputs = X_input)\n",
    "    relu1 = tf.nn.relu(bm1)\n",
    "    conv1 = tf.layers.conv2d(inputs = relu1, filters=num_filter, kernel_size=[3, 3], padding=\"SAME\", strides=stride, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    bm2 = tf.layers.batch_normalization(inputs = conv1)\n",
    "    relu2 = tf.nn.relu(bm2)\n",
    "    conv2 = tf.layers.conv2d(inputs = relu2, filters=num_filter, kernel_size=[3, 3], padding=\"SAME\", strides=1, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "    X_output = conv2 + shortcut\n",
    "        \n",
    "    return X_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x,by) :\n",
    "    \n",
    "    with tf.variable_scope('first'):\n",
    "        outs = tf.layers.conv2d(inputs = x, filters = 64, kernel_size=[7,7], padding=\"SAME\", strides=2)\n",
    "        outs = tf.layers.batch_normalization(inputs = outs)\n",
    "        outs = tf.nn.relu(outs)\n",
    "    \n",
    "#     #pooling    \n",
    "    outs = tf.layers.max_pooling2d(inputs = outs, strides = 2, pool_size=2)\n",
    "    \n",
    "    \n",
    "    outs = residual_block(outs, 64, False)\n",
    "    outs = residual_block(outs, 64, False)\n",
    "    outs = residual_block(outs, 64, False)\n",
    "\n",
    "    outs = residual_block(outs, 128, True)\n",
    "    outs = residual_block(outs, 128, False)\n",
    "    outs = residual_block(outs, 128, False)\n",
    "    outs = residual_block(outs, 128, False)\n",
    "\n",
    "    outs = residual_block(outs, 256, True)\n",
    "    outs = residual_block(outs, 256, False)\n",
    "    outs = residual_block(outs, 256, False)\n",
    "    outs = residual_block(outs, 256, False)\n",
    "    outs = residual_block(outs, 256, False)\n",
    "    outs = residual_block(outs, 256, False)\n",
    "                                   \n",
    "    outs = residual_block(outs, 512, True)\n",
    "    outs = residual_block(outs, 512, False)인\n",
    "    outs = residual_block(outs, 512, False)\n",
    "\n",
    "    #Average Pooling\n",
    "    outs = tf.reduce_mean(outs, [1, 2], keep_dims=True)\n",
    "\n",
    "    outs = tf.reshape(outs, (-1, outs.shape[1]*outs.shape[2]*outs.shape[3]))\n",
    "    outs = tf.layers.dense(outs, 100)\n",
    "                                   \n",
    "    #one_hot\n",
    "    one_hot = tf.squeeze(tf.one_hot(by, 100),axis=1)\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=outs, labels=one_hot))\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=0.0005).minimize(loss)\n",
    "    preds = tf.equal(tf.argmax(outs, 1), tf.argmax(one_hot, 1))     \n",
    "    acc = tf.reduce_mean(tf.cast(preds, tf.float32))\n",
    "    init = tf.global_variables_initializer()\n",
    "                                   \n",
    "    return {\n",
    "        'loss':loss,\n",
    "        'opt':opt,\n",
    "        'preds':preds,\n",
    "        'acc':acc,\n",
    "        'init':init\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-69bd761b636d>:33: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From <ipython-input-5-69bd761b636d>:41: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, 32, 32, 3))\n",
    "by = tf.placeholder(tf.int32)\n",
    "\n",
    "renset = model(X, by)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training_Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration 1\n",
      "loss 4.5893 acc 0.0100\n",
      "loss 4.1450 acc 0.0600\n",
      "loss 4.0298 acc 0.0700\n",
      "loss 3.8202 acc 0.1000\n",
      "loss 3.6191 acc 0.1300\n",
      "Current iteration 2\n",
      "loss 3.4040 acc 0.2200\n",
      "loss 3.2303 acc 0.1600\n",
      "loss 3.0017 acc 0.3000\n",
      "loss 3.0967 acc 0.2700\n",
      "loss 3.0202 acc 0.2400\n",
      "Current iteration 3\n",
      "loss 2.8458 acc 0.2700\n",
      "loss 2.6900 acc 0.2700\n",
      "loss 2.4920 acc 0.3600\n",
      "loss 2.5669 acc 0.3700\n",
      "loss 2.5829 acc 0.3200\n",
      "Current iteration 4\n",
      "loss 2.4350 acc 0.3700\n",
      "loss 2.5194 acc 0.3700\n",
      "loss 2.1125 acc 0.4500\n",
      "loss 2.2037 acc 0.4100\n",
      "loss 2.2563 acc 0.3700\n",
      "Current iteration 5\n",
      "loss 2.0609 acc 0.4400\n",
      "loss 2.0794 acc 0.4700\n",
      "loss 1.7399 acc 0.5300\n",
      "loss 1.7680 acc 0.5100\n",
      "loss 1.9543 acc 0.4200\n",
      "Current iteration 6\n",
      "loss 1.6155 acc 0.5300\n",
      "loss 1.7826 acc 0.4600\n",
      "loss 1.5224 acc 0.6200\n",
      "loss 1.3040 acc 0.6200\n",
      "loss 1.5053 acc 0.5700\n",
      "Current iteration 7\n",
      "loss 1.3484 acc 0.6300\n",
      "loss 1.3915 acc 0.6800\n",
      "loss 1.0346 acc 0.6600\n",
      "loss 1.0463 acc 0.6900\n",
      "loss 1.0171 acc 0.7300\n",
      "Current iteration 8\n",
      "loss 1.1492 acc 0.6800\n",
      "loss 0.8906 acc 0.7500\n",
      "loss 0.8889 acc 0.7600\n",
      "loss 0.7195 acc 0.7700\n",
      "loss 0.8644 acc 0.7600\n",
      "Current iteration 9\n",
      "loss 0.7791 acc 0.7900\n",
      "loss 0.8234 acc 0.7500\n",
      "loss 0.6309 acc 0.7900\n",
      "loss 0.5941 acc 0.8400\n",
      "loss 0.7065 acc 0.8100\n",
      "Current iteration 10\n",
      "loss 0.6399 acc 0.8100\n",
      "loss 0.6317 acc 0.8300\n",
      "loss 0.5387 acc 0.8600\n",
      "loss 0.4444 acc 0.8600\n",
      "loss 0.5388 acc 0.8500\n",
      "Current iteration 11\n",
      "loss 0.3448 acc 0.9100\n",
      "loss 0.4960 acc 0.8500\n",
      "loss 0.3790 acc 0.8900\n",
      "loss 0.3357 acc 0.8800\n",
      "loss 0.3153 acc 0.8800\n",
      "Current iteration 12\n",
      "loss 0.4499 acc 0.8200\n",
      "loss 0.1599 acc 0.9400\n",
      "loss 0.1855 acc 0.9400\n",
      "loss 0.2038 acc 0.9500\n",
      "loss 0.2349 acc 0.9200\n",
      "Current iteration 13\n",
      "loss 0.2001 acc 0.9400\n",
      "loss 0.3427 acc 0.8900\n",
      "loss 0.2187 acc 0.9300\n",
      "loss 0.0910 acc 0.9600\n",
      "loss 0.3153 acc 0.8900\n",
      "Current iteration 14\n",
      "loss 0.2928 acc 0.9000\n",
      "loss 0.2562 acc 0.9200\n",
      "loss 0.1324 acc 0.9700\n",
      "loss 0.3198 acc 0.8900\n",
      "loss 0.2781 acc 0.9300\n",
      "Current iteration 15\n",
      "loss 0.1367 acc 0.9600\n",
      "loss 0.1528 acc 0.9500\n",
      "loss 0.3207 acc 0.8800\n",
      "loss 0.2002 acc 0.9300\n",
      "loss 0.1064 acc 0.9700\n",
      "Current iteration 16\n",
      "loss 0.2856 acc 0.9400\n",
      "loss 0.2064 acc 0.9300\n",
      "loss 0.2107 acc 0.9700\n",
      "loss 0.1275 acc 0.9400\n",
      "loss 0.1222 acc 0.9600\n",
      "Current iteration 17\n",
      "loss 0.1268 acc 0.9700\n",
      "loss 0.1843 acc 0.9700\n",
      "loss 0.1555 acc 0.9500\n",
      "loss 0.1545 acc 0.9500\n",
      "loss 0.1642 acc 0.9400\n",
      "Current iteration 18\n",
      "loss 0.2053 acc 0.9200\n",
      "loss 0.2432 acc 0.9200\n",
      "loss 0.0955 acc 0.9700\n",
      "loss 0.0910 acc 0.9800\n",
      "loss 0.1390 acc 0.9700\n",
      "Current iteration 19\n",
      "loss 0.2533 acc 0.9200\n",
      "loss 0.1432 acc 0.9500\n",
      "loss 0.1926 acc 0.9500\n",
      "loss 0.3179 acc 0.8700\n",
      "loss 0.3447 acc 0.8800\n",
      "Current iteration 20\n",
      "loss 0.1871 acc 0.9500\n",
      "loss 0.0626 acc 0.9800\n",
      "loss 0.1116 acc 0.9600\n",
      "loss 0.2000 acc 0.9500\n",
      "loss 0.1509 acc 0.9600\n",
      "Current iteration 21\n",
      "loss 0.0483 acc 0.9900\n",
      "loss 0.1760 acc 0.9700\n",
      "loss 0.1766 acc 0.9400\n",
      "loss 0.1001 acc 0.9600\n",
      "loss 0.0920 acc 0.9800\n",
      "Current iteration 22\n",
      "loss 0.0892 acc 0.9600\n",
      "loss 0.1329 acc 0.9700\n",
      "loss 0.0808 acc 0.9700\n",
      "loss 0.1590 acc 0.9400\n",
      "loss 0.1321 acc 0.9600\n",
      "Current iteration 23\n",
      "loss 0.2099 acc 0.9500\n",
      "loss 0.2136 acc 0.9600\n",
      "loss 0.1026 acc 0.9700\n",
      "loss 0.1234 acc 0.9700\n",
      "loss 0.1221 acc 0.9600\n",
      "Current iteration 24\n",
      "loss 0.0701 acc 0.9800\n",
      "loss 0.0752 acc 0.9800\n",
      "loss 0.1978 acc 0.9400\n",
      "loss 0.0923 acc 0.9800\n",
      "loss 0.0987 acc 0.9700\n",
      "Current iteration 25\n",
      "loss 0.1305 acc 0.9500\n",
      "loss 0.1601 acc 0.9500\n",
      "loss 0.1892 acc 0.9400\n",
      "loss 0.0440 acc 0.9700\n",
      "loss 0.1860 acc 0.9700\n",
      "Current iteration 26\n",
      "loss 0.0963 acc 0.9700\n",
      "loss 0.1067 acc 0.9600\n",
      "loss 0.1159 acc 0.9600\n",
      "loss 0.1561 acc 0.9400\n",
      "loss 0.0905 acc 0.9700\n",
      "Current iteration 27\n",
      "loss 0.1631 acc 0.9600\n",
      "loss 0.1221 acc 0.9400\n",
      "loss 0.0406 acc 0.9800\n",
      "loss 0.0906 acc 0.9800\n",
      "loss 0.0855 acc 0.9800\n",
      "Current iteration 28\n",
      "loss 0.1010 acc 0.9500\n",
      "loss 0.2947 acc 0.9100\n",
      "loss 0.1888 acc 0.9400\n",
      "loss 0.0605 acc 0.9700\n",
      "loss 0.0716 acc 0.9800\n",
      "Current iteration 29\n",
      "loss 0.0684 acc 0.9900\n",
      "loss 0.0941 acc 0.9600\n",
      "loss 0.1433 acc 0.9700\n",
      "loss 0.0992 acc 0.9700\n",
      "loss 0.0832 acc 0.9600\n",
      "Current iteration 30\n",
      "loss 0.0246 acc 0.9900\n",
      "loss 0.0664 acc 0.9700\n",
      "loss 0.1164 acc 0.9700\n",
      "loss 0.0736 acc 0.9800\n",
      "loss 0.1157 acc 0.9600\n",
      "TEST: loss 5.6568 acc 0.3239\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "batch_size = 100\n",
    "num_display = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(renset['init'])\n",
    "    for ind_epoch in range(0, num_epochs):\n",
    "        print('Current iteration {}'.format(ind_epoch + 1))\n",
    "\n",
    "        for ind_ in range(0, int(50000 / batch_size)):\n",
    "            batch_X = train_data[ind_*batch_size:(ind_+1)*batch_size]\n",
    "            batch_by = train_label[ind_*batch_size:(ind_+1)*batch_size]\n",
    "            _, cur_loss, cur_acc = sess.run(\n",
    "                [renset['opt'], renset['loss'], renset['acc']],\n",
    "                feed_dict={X: batch_X, by: batch_by})\n",
    "            if ind_ % num_display == 0:\n",
    "                print('loss {0:.4f} acc {1:.4f}'.format(cur_loss, cur_acc))\n",
    "    cur_acc_all = 0.0\n",
    "    cur_loss_all = 0.0\n",
    "    for ind_ in range(0, 10):\n",
    "        cur_loss, cur_acc = sess.run(\n",
    "                    [renset['loss'], renset['acc']],\n",
    "                    feed_dict={X: test_data[ind_*1000:(ind_+1)*1000], \n",
    "                               by: test_label[ind_*1000:(ind_+1)*1000]})\n",
    "        cur_loss_all += cur_loss\n",
    "        cur_acc_all += cur_acc\n",
    "    print('TEST: loss {0:.4f} acc {1:.4f}'.format(cur_loss_all / 10.0, \n",
    "                                                  cur_acc_all / 10.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
