{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar100\n",
    "import os\n",
    "import sys\n",
    "from six.moves import urllib\n",
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get Data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data(label_mode='fine')\n",
    "x_train = x_train / 255.0\n",
    "x_test =  x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# size of MNIST\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5b781a77b8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # show data\n",
    "_, (ax1) = plt.subplots(1)\n",
    "sample_data = x_train[0]\n",
    "ax1.imshow(sample_data, cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x_input, num_filter, chg_dim):\n",
    "    \"\"\"\n",
    "    input -> Conv -> BN -> ReLU -> Conv -> BN -> Addition -> ReLU -> output\n",
    "    :param input_layer: Usually previous layer\n",
    "    :param filter: (width<int>, height<int>) The size of the filter\n",
    "    :param channel: [in_channels, out_channels]\n",
    "    :param stride: The size of the s\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    stride = 1\n",
    "    \n",
    "    # stride가 2일 경우\n",
    "    if chg_dim:\n",
    "        stride = 2\n",
    "        pool1 = tf.layers.max_pooling2d(inputs= x_input, strides=2, pool_size=[2,2])\n",
    "        pad1 = tf.pad(pool1, [[0,0],[0,0],[0,0],[int(num_filter/4),int(num_filter/4)]])\n",
    "        shortcut = pad1\n",
    "    else:\n",
    "        shortcut = x_input\n",
    "        \n",
    "    b_n1 = tf.layers.batch_normalization(inputs = x_input)\n",
    "    relu1 = tf.nn.relu(b_n1)\n",
    "    conv1 = tf.layers.conv2d(inputs = relu1, \n",
    "                             filters = num_filter, \n",
    "                             kernel_size = [3,3], \n",
    "                             padding = \"SAME\",\n",
    "                            strides=stride,\n",
    "                            kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b_n2 = tf.layers.batch_normalization(inputs = conv1)\n",
    "    relu2 = tf.nn.relu(b_n2)\n",
    "    conv2 = tf.layers.conv2d(inputs = relu2, filters=num_filter,\n",
    "                            kernel_size=[3,3],\n",
    "                            padding=\"SAME\",\n",
    "                            strides=1,\n",
    "                            kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "    x_output = conv2 + shortcut\n",
    "    \n",
    "    return x_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, by):\n",
    "    with tf.variable_scope('input_scope'):\n",
    "        h = tf.layers.conv2d(inputs = x, filters = 64, kernel_size=[7,7], padding=\"SAME\", strides=2)\n",
    "        h = tf.layers.batch_normalization(inputs = h)\n",
    "        h = tf.nn.relu(h)\n",
    "    \n",
    "    # Pooling layer\n",
    "    h = tf.layers.max_pooling2d(inputs = h, strides = 2, pool_size=2)\n",
    "        \n",
    "    with tf.variable_scope('residual01'),tf.device('/device:GPU:0'):\n",
    "        h = residual_block(h, 64, False)\n",
    "        h = residual_block(h, 64, False)\n",
    "        h = residual_block(h, 64, False)\n",
    "        h = residual_block(h, 64, False)\n",
    "        h = residual_block(h, 64, False)\n",
    "        h = residual_block(h, 64, False)\n",
    "        \n",
    "    with tf.variable_scope('residual02'),tf.device('/device:GPU:0'):\n",
    "        #h = tf.layers.max_pooling2d(inputs = h, strides = 2, pool_size=2)\n",
    "        h = residual_block(h, 128, True)\n",
    "        h = residual_block(h, 128, False)\n",
    "        h = residual_block(h, 128, False)\n",
    "        h = residual_block(h, 128, False)\n",
    "        h = residual_block(h, 128, False)\n",
    "        h = residual_block(h, 128, False)\n",
    "        h = residual_block(h, 128, False)\n",
    "        h = residual_block(h, 128, False)\n",
    "        \n",
    "    with tf.variable_scope('residual03'),tf.device('/device:GPU:0'):\n",
    "        h = residual_block(h, 256, True)\n",
    "        h = residual_block(h, 256, False)\n",
    "        h = residual_block(h, 256, False)\n",
    "        h = residual_block(h, 256, False)\n",
    "        h = residual_block(h, 256, False)\n",
    "        h = residual_block(h, 256, False)\n",
    "        h = residual_block(h, 256, False)\n",
    "        h = residual_block(h, 256, False)\n",
    "        h = residual_block(h, 256, False)\n",
    "        h = residual_block(h, 256, False)\n",
    "        h = residual_block(h, 256, False)\n",
    "        h = residual_block(h, 256, False)\n",
    "        h = residual_block(h, 256, False)\n",
    "    \n",
    "    with tf.variable_scope('residual04'),tf.device('/device:GPU:0'):\n",
    "        h = residual_block(h, 512, True)\n",
    "        h = residual_block(h, 512, False)\n",
    "        h = residual_block(h, 512, False)\n",
    "        h = residual_block(h, 512, False)\n",
    "        h = residual_block(h, 512, False)\n",
    "        h = residual_block(h, 512, False)\n",
    "    \n",
    "\n",
    "    # Average Pooling\n",
    "    h = tf.reduce_mean(h, [1,2], keep_dims=True)\n",
    "    h = tf.reshape(h,(-1, h.shape[1] * h.shape[2] * h.shape[3]))\n",
    "    h = tf.layers.dense(h, 100)\n",
    "    \n",
    "    # One hot\n",
    "    one_hot = tf.one_hot(by,100)\n",
    "    one_hot = tf.reshape(one_hot, [-1, 100])\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits = h,\n",
    "        labels= one_hot))\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=0.0005).minimize(loss)\n",
    "    softmax = tf.nn.softmax(h)\n",
    "    preds = tf.argmax(softmax, axis=1)\n",
    "    acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(one_hot,1), preds), tf.float32))\n",
    "#     preds = tf.equal(tf.argmax(h,1),tf.argmax(one_hot,1))\n",
    "#     acc = tf.reduce_mean(tf.cast(preds, tf.float32))\n",
    "    init = tf.global_variables_initializer()\n",
    "        \n",
    "    return {\n",
    "        'loss' : loss,\n",
    "        'opt' : opt,\n",
    "        'preds' : preds,\n",
    "        'acc' : acc,\n",
    "        'init' : init\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-287ecf6bfec5>:54: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From <ipython-input-5-287ecf6bfec5>:63: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, 32, 32, 3))\n",
    "by = tf.placeholder(tf.int64)\n",
    "\n",
    "resnet = model(X,by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration 1\n",
      "loss 5.2764 acc 0.0100\n",
      "loss 4.2790 acc 0.0300\n",
      "loss 4.1513 acc 0.0300\n",
      "loss 4.0081 acc 0.0800\n",
      "loss 3.8777 acc 0.1000\n",
      "Current iteration 2\n",
      "loss 3.6917 acc 0.1200\n",
      "loss 3.3579 acc 0.1600\n",
      "loss 3.4063 acc 0.2100\n",
      "loss 3.4252 acc 0.2400\n",
      "loss 3.2867 acc 0.1300\n",
      "Current iteration 3\n",
      "loss 3.1931 acc 0.2200\n",
      "loss 3.0180 acc 0.2400\n",
      "loss 2.9097 acc 0.3000\n",
      "loss 2.9083 acc 0.2900\n",
      "loss 2.9049 acc 0.2700\n",
      "Current iteration 4\n",
      "loss 2.8356 acc 0.3000\n",
      "loss 2.6191 acc 0.3200\n",
      "loss 2.4321 acc 0.3400\n",
      "loss 2.5241 acc 0.3500\n",
      "loss 2.5878 acc 0.2800\n",
      "Current iteration 5\n",
      "loss 2.4573 acc 0.4000\n",
      "loss 2.2506 acc 0.3600\n",
      "loss 1.9144 acc 0.4400\n",
      "loss 2.0215 acc 0.5000\n",
      "loss 2.3708 acc 0.3400\n",
      "Current iteration 6\n",
      "loss 2.1771 acc 0.3900\n",
      "loss 1.7872 acc 0.4200\n",
      "loss 1.5774 acc 0.5600\n",
      "loss 1.5519 acc 0.6100\n",
      "loss 1.7230 acc 0.4900\n",
      "Current iteration 7\n",
      "loss 1.6863 acc 0.5100\n",
      "loss 1.2534 acc 0.6000\n",
      "loss 1.5475 acc 0.5500\n",
      "loss 1.3635 acc 0.6600\n",
      "loss 1.4190 acc 0.5700\n",
      "Current iteration 8\n",
      "loss 1.0602 acc 0.7200\n",
      "loss 1.0654 acc 0.6900\n",
      "loss 1.2158 acc 0.7000\n",
      "loss 1.2298 acc 0.6700\n",
      "loss 1.2502 acc 0.6300\n",
      "Current iteration 9\n",
      "loss 0.8483 acc 0.7100\n",
      "loss 0.9692 acc 0.7300\n",
      "loss 0.7886 acc 0.8000\n",
      "loss 0.9269 acc 0.7000\n",
      "loss 0.7187 acc 0.7900\n",
      "Current iteration 10\n",
      "loss 0.7393 acc 0.8000\n",
      "loss 0.5602 acc 0.8200\n",
      "loss 0.5122 acc 0.8900\n",
      "loss 0.5447 acc 0.8100\n",
      "loss 0.5250 acc 0.8800\n",
      "Current iteration 11\n",
      "loss 0.5618 acc 0.8600\n",
      "loss 0.3254 acc 0.9300\n",
      "loss 0.3931 acc 0.9100\n",
      "loss 0.3935 acc 0.8700\n",
      "loss 0.4241 acc 0.8800\n",
      "Current iteration 12\n",
      "loss 0.2784 acc 0.9100\n",
      "loss 0.2865 acc 0.9300\n",
      "loss 0.3825 acc 0.8800\n",
      "loss 0.2486 acc 0.9200\n",
      "loss 0.4781 acc 0.8800\n",
      "Current iteration 13\n",
      "loss 0.1507 acc 0.9600\n",
      "loss 0.2482 acc 0.9300\n",
      "loss 0.1926 acc 0.9400\n",
      "loss 0.3023 acc 0.9000\n",
      "loss 0.2646 acc 0.9100\n",
      "Current iteration 14\n",
      "loss 0.1939 acc 0.9200\n",
      "loss 0.3172 acc 0.9100\n",
      "loss 0.2889 acc 0.9200\n",
      "loss 0.1510 acc 0.9700\n",
      "loss 0.2741 acc 0.8800\n",
      "Current iteration 15\n",
      "loss 0.2020 acc 0.9200\n",
      "loss 0.4598 acc 0.9100\n",
      "loss 0.1206 acc 0.9600\n",
      "loss 0.1323 acc 0.9600\n",
      "loss 0.2036 acc 0.9300\n",
      "Current iteration 16\n",
      "loss 0.2105 acc 0.9300\n",
      "loss 0.1305 acc 0.9500\n",
      "loss 0.0859 acc 0.9700\n",
      "loss 0.2137 acc 0.9300\n",
      "loss 0.1857 acc 0.9600\n",
      "Current iteration 17\n",
      "loss 0.3321 acc 0.8600\n",
      "loss 0.2415 acc 0.9300\n",
      "loss 0.0841 acc 0.9800\n",
      "loss 0.2798 acc 0.9400\n",
      "loss 0.2992 acc 0.9200\n",
      "Current iteration 18\n",
      "loss 0.5967 acc 0.9200\n",
      "loss 0.1888 acc 0.9200\n",
      "loss 0.2961 acc 0.9000\n",
      "loss 0.1577 acc 0.9400\n",
      "loss 0.1840 acc 0.9400\n",
      "Current iteration 19\n",
      "loss 0.1349 acc 0.9600\n",
      "loss 0.0856 acc 0.9700\n",
      "loss 0.0873 acc 0.9800\n",
      "loss 0.1558 acc 0.9600\n",
      "loss 0.1472 acc 0.9400\n",
      "Current iteration 20\n",
      "loss 0.1799 acc 0.9500\n",
      "loss 0.3151 acc 0.9200\n",
      "loss 0.1645 acc 0.9400\n",
      "loss 0.1586 acc 0.9500\n",
      "loss 0.1338 acc 0.9600\n",
      "Current iteration 21\n",
      "loss 0.1803 acc 0.9500\n",
      "loss 0.1478 acc 0.9700\n",
      "loss 0.2517 acc 0.9200\n",
      "loss 0.3325 acc 0.9200\n",
      "loss 0.1918 acc 0.9600\n",
      "Current iteration 22\n",
      "loss 0.2117 acc 0.9300\n",
      "loss 0.1381 acc 0.9500\n",
      "loss 0.0636 acc 0.9800\n",
      "loss 0.0609 acc 0.9900\n",
      "loss 0.1448 acc 0.9600\n",
      "Current iteration 23\n",
      "loss 0.1276 acc 0.9800\n",
      "loss 0.0915 acc 0.9900\n",
      "loss 0.0801 acc 0.9600\n",
      "loss 0.0727 acc 0.9700\n",
      "loss 0.1011 acc 0.9700\n",
      "Current iteration 24\n",
      "loss 0.0748 acc 0.9700\n",
      "loss 0.1902 acc 0.9400\n",
      "loss 0.0900 acc 0.9800\n",
      "loss 0.1302 acc 0.9400\n",
      "loss 0.0783 acc 0.9800\n",
      "Current iteration 25\n",
      "loss 0.2248 acc 0.9200\n",
      "loss 0.2540 acc 0.9300\n",
      "loss 0.0532 acc 0.9900\n",
      "loss 0.1195 acc 0.9600\n",
      "loss 0.1293 acc 0.9700\n",
      "Current iteration 26\n",
      "loss 0.1856 acc 0.9500\n",
      "loss 0.1825 acc 0.9500\n",
      "loss 0.0904 acc 0.9600\n",
      "loss 0.0453 acc 0.9900\n",
      "loss 0.3636 acc 0.9100\n",
      "Current iteration 27\n",
      "loss 0.1345 acc 0.9600\n",
      "loss 0.1051 acc 0.9600\n",
      "loss 0.2223 acc 0.9500\n",
      "loss 0.1679 acc 0.9500\n",
      "loss 0.2601 acc 0.9200\n",
      "Current iteration 28\n",
      "loss 0.0963 acc 0.9700\n",
      "loss 0.2093 acc 0.9500\n",
      "loss 0.1707 acc 0.9400\n",
      "loss 0.1009 acc 0.9600\n",
      "loss 0.1232 acc 0.9900\n",
      "Current iteration 29\n",
      "loss 0.1666 acc 0.9500\n",
      "loss 0.1095 acc 0.9800\n",
      "loss 0.1182 acc 0.9500\n",
      "loss 0.0790 acc 0.9900\n",
      "loss 0.0801 acc 0.9700\n",
      "Current iteration 30\n",
      "loss 0.0997 acc 0.9600\n",
      "loss 0.0781 acc 0.9800\n",
      "loss 0.1493 acc 0.9500\n",
      "loss 0.0630 acc 0.9800\n",
      "loss 0.1462 acc 0.9600\n",
      "TEST: loss 5.9802 acc 0.2904\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "batch_size = 100\n",
    "num_display = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(resnet['init'])\n",
    "    for ind_epoch in range(0, num_epochs):\n",
    "        print('Current iteration {}'.format(ind_epoch + 1))\n",
    "\n",
    "        for ind_ in range(0, int(50000 / batch_size)):\n",
    "            batch_X = x_train[ind_*batch_size:(ind_+1)*batch_size]\n",
    "            batch_by = y_train[ind_*batch_size:(ind_+1)*batch_size]\n",
    "            _, cur_loss, cur_acc = sess.run(\n",
    "                [resnet['opt'], resnet['loss'], resnet['acc']],\n",
    "                feed_dict={X: batch_X, by: batch_by})\n",
    "            if ind_ % num_display == 0:\n",
    "                print('loss {0:.4f} acc {1:.4f}'.format(cur_loss, cur_acc))\n",
    "    cur_acc_all = 0.0\n",
    "    cur_loss_all = 0.0\n",
    "    for ind_ in range(0, 10):\n",
    "        cur_loss, cur_acc = sess.run(\n",
    "                    [resnet['loss'], resnet['acc']],\n",
    "                    feed_dict={X: x_test[ind_*1000:(ind_+1)*1000], \n",
    "                               by: y_test[ind_*1000:(ind_+1)*1000]})\n",
    "        cur_loss_all += cur_loss\n",
    "        cur_acc_all += cur_acc\n",
    "    print('TEST: loss {0:.4f} acc {1:.4f}'.format(cur_loss_all / 10.0, \n",
    "                                                  cur_acc_all / 10.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
